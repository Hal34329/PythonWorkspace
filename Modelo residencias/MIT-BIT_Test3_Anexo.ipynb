{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Decrease Impurity (MDI), o en español, Disminución Media de la Impureza, es una técnica utilizada para medir la importancia de las variables en modelos basados en árboles, como Random Forests y árboles de decisión.\n",
    "\n",
    "__¿Cómo funciona?__\n",
    "\n",
    "__1. Impureza:__ Cada nodo en un árbol de decisión tiene una medida de impureza, que indica cuán mezcladas están las clases en ese nodo. Un nodo puro tendría solo una clase, mientras que un nodo impuro tendría una mezcla de clases. Se usan métricas como el índice de Gini o la entropía para cuantificar la impureza.\n",
    "\n",
    "__2. Disminución de la impureza:__ Cuando se hace una división en un nodo usando una variable, la impureza de los nodos hijos resultantes suele ser menor que la del nodo padre. Esta diferencia es la \"disminución de la impureza\" atribuida a esa variable.\n",
    "\n",
    "__3. Promediando la disminución:__ Para cada variable, se calcula la disminución de la impureza en cada nodo donde se usa para hacer una división. Luego, se promedia esta disminución en todos los árboles del modelo (en el caso de un Random Forest). Esta media es la \"Disminución Media de la Impureza\" (MDI).\n",
    "\n",
    "__En resumen, MDI mide cuánto una variable en promedio reduce la impureza en el modelo.__ Una variable con un MDI alto es considerada más importante porque contribuye más a la capacidad del modelo de separar las clases o predecir el valor objetivo.\n",
    "\n",
    "__Ejemplo:__\n",
    "\n",
    "Imagina un modelo que predice si un cliente comprará un producto. Si la variable \"edad\" tiene un MDI alto, significa que las divisiones basadas en la edad del cliente tienden a generar nodos más puros, lo que indica que la edad es un factor importante para predecir la compra.\n",
    "\n",
    "__Limitaciones:__\n",
    "\n",
    "* MDI puede estar sesgada hacia variables con más categorías.\n",
    "* Puede sobreestimar la importancia de variables correlacionadas.\n",
    "A pesar de estas limitaciones, MDI es una herramienta útil para entender la importancia de las variables en modelos basados en árboles. Espero que esto te ayude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entiendo. Los resultados que estás obteniendo de `treeinterpreter` representan la contribución de cada característica a la predicción para una instancia específica.\n",
    "\n",
    "En tu ejemplo:\n",
    "\n",
    "* `0_pre-RR`: La contribución de la característica \"0_pre-RR\" a la predicción. `[-0.1751713 0.1751713]` indica que esta característica tiene un impacto negativo en la probabilidad de la clase 0 y un impacto positivo en la probabilidad de la clase 1.\n",
    "* `0_post-RR`: La contribución de la característica \"0_post-RR\" a la predicción. `[ 0.15818206 -0.15818206]` indica que esta característica tiene un impacto positivo en la probabilidad de la clase 0 y un impacto negativo en la probabilidad de la clase 1.\n",
    "* `0_pPeak`: La contribución de la característica \"0_pPeak\" a la predicción. `[-0.03357757 0.03357757]` indica un impacto negativo en la clase 0 y positivo en la clase 1.\n",
    "\n",
    "**Interpretación:**\n",
    "\n",
    "* **Magnitud:** La magnitud de los valores (ignorando el signo) indica la importancia de la característica. Valores más grandes (en valor absoluto) indican una mayor influencia en la predicción.\n",
    "* **Signo:** El signo del valor indica la dirección del impacto.\n",
    "    * **Positivo:** La característica aumenta la probabilidad de la clase correspondiente.\n",
    "    * **Negativo:** La característica disminuye la probabilidad de la clase correspondiente.\n",
    "\n",
    "**En tu caso:**\n",
    "\n",
    "* \"0_pre-RR\" tiene el mayor impacto en la predicción, disminuyendo la probabilidad de la clase 0 y aumentando la de la clase 1.\n",
    "* \"0_post-RR\" tiene un impacto moderado, aumentando la probabilidad de la clase 0 y disminuyendo la de la clase 1.\n",
    "* \"0_pPeak\" tiene un impacto menor, con un efecto similar al de \"0_pre-RR\" pero en menor escala.\n",
    "\n",
    "**Para extraer reglas:**\n",
    "\n",
    "Puedes combinar estas contribuciones para entender las reglas de decisión del modelo. Por ejemplo, si una instancia tiene un valor alto de \"0_pre-RR\" y un valor bajo de \"0_post-RR\", es más probable que sea clasificada como clase 1.\n",
    "\n",
    "**Recuerda:**\n",
    "\n",
    "* Estas contribuciones son específicas para una instancia en particular. Para obtener una visión general del modelo, deberías analizar las contribuciones para varias instancias.\n",
    "* La interpretación de las reglas puede requerir conocimiento del dominio del problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es normal que los dos valores de contribución para una característica en `treeinterpreter` tengan la misma magnitud pero con signo opuesto en un problema de clasificación binaria. Esto se debe a que la suma de las contribuciones de todas las características más el sesgo debe ser igual a la predicción final.\n",
    "\n",
    "En tu caso, `0_pre_RR` tiene una contribución de -0.234 para una clase y 0.234 para la otra. Esto indica que esta característica tiene un impacto opuesto en la probabilidad de cada clase. Por ejemplo, si un valor alto de `0_pre_RR` aumenta la probabilidad de la clase 0, también disminuirá la probabilidad de la clase 1 en la misma magnitud.\n",
    "\n",
    "Aquí te dejo un ejemplo para ilustrarlo:\n",
    "\n",
    "* Supongamos que el sesgo es 0.5 (probabilidad inicial de la clase 0).\n",
    "* Si `0_pre_RR` tiene una contribución de -0.234, la probabilidad de la clase 0 se reduce a 0.266 (0.5 - 0.234).\n",
    "* Al mismo tiempo, la probabilidad de la clase 1 aumenta a 0.734 (1 - 0.266), que es equivalente a 0.5 + 0.234.\n",
    "En resumen, el comportamiento que estás observando es normal en un problema de clasificación binaria con `treeinterpreter`. Las contribuciones con la misma magnitud pero signo opuesto reflejan el impacto opuesto de la característica en la probabilidad de cada clase.\n",
    "\n",
    "Si observas este patrón en todas las características, significa que el modelo está utilizando las características para discriminar entre las dos clases de manera efectiva.\n",
    "\n",
    "Espero que esta explicación te ayude a comprender mejor el significado de las contribuciones en `treeinterpreter.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entiendo. El error \"UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\" indica que el objeto MinMaxScaler se ajustó con datos que tenían nombres de características (columnas), pero ahora se está utilizando para transformar datos que no tienen nombres de características.\n",
    "\n",
    "Esto puede suceder si estás utilizando un DataFrame de Pandas para entrenar el modelo y ajustar el escalador, pero luego estás utilizando un array NumPy para hacer predicciones. Los arrays NumPy no tienen nombres de características, por lo que el escalador no puede encontrar las características que espera.\n",
    "\n",
    "Para solucionar este problema, puedes intentar lo siguiente:\n",
    "\n",
    "1. Utilizar un DataFrame de Pandas para hacer predicciones:\n",
    "Si es posible, utiliza un DataFrame de Pandas para almacenar los datos de entrada que se utilizarán para hacer predicciones. Asegúrate de que el DataFrame tenga los mismos nombres de columnas que el DataFrame que se utilizó para entrenar el modelo y ajustar el escalador.\n",
    "\n",
    "2. Asignar nombres de características al array NumPy:\n",
    "Si no puedes utilizar un DataFrame de Pandas, puedes asignar nombres de características al array NumPy utilizando la función np.array con el argumento dtype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.array(input_data, dtype=[('feature1', float), ('feature2', float), ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reemplaza feature1, feature2, etc. con los nombres de las características que espera el escalador.\n",
    "\n",
    "3. Ignorar la advertencia:\n",
    "Si la advertencia no afecta el rendimiento del modelo, puedes ignorarla utilizando la función warnings.filterwarnings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', message='X does not have valid feature names, but')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
