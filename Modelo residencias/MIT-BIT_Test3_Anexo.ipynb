{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Decrease Impurity (MDI), o en español, Disminución Media de la Impureza, es una técnica utilizada para medir la importancia de las variables en modelos basados en árboles, como Random Forests y árboles de decisión.\n",
    "\n",
    "__¿Cómo funciona?__\n",
    "\n",
    "__1. Impureza:__ Cada nodo en un árbol de decisión tiene una medida de impureza, que indica cuán mezcladas están las clases en ese nodo. Un nodo puro tendría solo una clase, mientras que un nodo impuro tendría una mezcla de clases. Se usan métricas como el índice de Gini o la entropía para cuantificar la impureza.\n",
    "\n",
    "__2. Disminución de la impureza:__ Cuando se hace una división en un nodo usando una variable, la impureza de los nodos hijos resultantes suele ser menor que la del nodo padre. Esta diferencia es la \"disminución de la impureza\" atribuida a esa variable.\n",
    "\n",
    "__3. Promediando la disminución:__ Para cada variable, se calcula la disminución de la impureza en cada nodo donde se usa para hacer una división. Luego, se promedia esta disminución en todos los árboles del modelo (en el caso de un Random Forest). Esta media es la \"Disminución Media de la Impureza\" (MDI).\n",
    "\n",
    "__En resumen, MDI mide cuánto una variable en promedio reduce la impureza en el modelo.__ Una variable con un MDI alto es considerada más importante porque contribuye más a la capacidad del modelo de separar las clases o predecir el valor objetivo.\n",
    "\n",
    "__Ejemplo:__\n",
    "\n",
    "Imagina un modelo que predice si un cliente comprará un producto. Si la variable \"edad\" tiene un MDI alto, significa que las divisiones basadas en la edad del cliente tienden a generar nodos más puros, lo que indica que la edad es un factor importante para predecir la compra.\n",
    "\n",
    "__Limitaciones:__\n",
    "\n",
    "* MDI puede estar sesgada hacia variables con más categorías.\n",
    "* Puede sobreestimar la importancia de variables correlacionadas.\n",
    "A pesar de estas limitaciones, MDI es una herramienta útil para entender la importancia de las variables en modelos basados en árboles. Espero que esto te ayude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entiendo. Los resultados que estás obteniendo de `treeinterpreter` representan la contribución de cada característica a la predicción para una instancia específica.\n",
    "\n",
    "En tu ejemplo:\n",
    "\n",
    "* `0_pre-RR`: La contribución de la característica \"0_pre-RR\" a la predicción. `[-0.1751713 0.1751713]` indica que esta característica tiene un impacto negativo en la probabilidad de la clase 0 y un impacto positivo en la probabilidad de la clase 1.\n",
    "* `0_post-RR`: La contribución de la característica \"0_post-RR\" a la predicción. `[ 0.15818206 -0.15818206]` indica que esta característica tiene un impacto positivo en la probabilidad de la clase 0 y un impacto negativo en la probabilidad de la clase 1.\n",
    "* `0_pPeak`: La contribución de la característica \"0_pPeak\" a la predicción. `[-0.03357757 0.03357757]` indica un impacto negativo en la clase 0 y positivo en la clase 1.\n",
    "\n",
    "**Interpretación:**\n",
    "\n",
    "* **Magnitud:** La magnitud de los valores (ignorando el signo) indica la importancia de la característica. Valores más grandes (en valor absoluto) indican una mayor influencia en la predicción.\n",
    "* **Signo:** El signo del valor indica la dirección del impacto.\n",
    "    * **Positivo:** La característica aumenta la probabilidad de la clase correspondiente.\n",
    "    * **Negativo:** La característica disminuye la probabilidad de la clase correspondiente.\n",
    "\n",
    "**En tu caso:**\n",
    "\n",
    "* \"0_pre-RR\" tiene el mayor impacto en la predicción, disminuyendo la probabilidad de la clase 0 y aumentando la de la clase 1.\n",
    "* \"0_post-RR\" tiene un impacto moderado, aumentando la probabilidad de la clase 0 y disminuyendo la de la clase 1.\n",
    "* \"0_pPeak\" tiene un impacto menor, con un efecto similar al de \"0_pre-RR\" pero en menor escala.\n",
    "\n",
    "**Para extraer reglas:**\n",
    "\n",
    "Puedes combinar estas contribuciones para entender las reglas de decisión del modelo. Por ejemplo, si una instancia tiene un valor alto de \"0_pre-RR\" y un valor bajo de \"0_post-RR\", es más probable que sea clasificada como clase 1.\n",
    "\n",
    "**Recuerda:**\n",
    "\n",
    "* Estas contribuciones son específicas para una instancia en particular. Para obtener una visión general del modelo, deberías analizar las contribuciones para varias instancias.\n",
    "* La interpretación de las reglas puede requerir conocimiento del dominio del problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es normal que los dos valores de contribución para una característica en `treeinterpreter` tengan la misma magnitud pero con signo opuesto en un problema de clasificación binaria. Esto se debe a que la suma de las contribuciones de todas las características más el sesgo debe ser igual a la predicción final.\n",
    "\n",
    "En tu caso, `0_pre_RR` tiene una contribución de -0.234 para una clase y 0.234 para la otra. Esto indica que esta característica tiene un impacto opuesto en la probabilidad de cada clase. Por ejemplo, si un valor alto de `0_pre_RR` aumenta la probabilidad de la clase 0, también disminuirá la probabilidad de la clase 1 en la misma magnitud.\n",
    "\n",
    "Aquí te dejo un ejemplo para ilustrarlo:\n",
    "\n",
    "* Supongamos que el sesgo es 0.5 (probabilidad inicial de la clase 0).\n",
    "* Si `0_pre_RR` tiene una contribución de -0.234, la probabilidad de la clase 0 se reduce a 0.266 (0.5 - 0.234).\n",
    "* Al mismo tiempo, la probabilidad de la clase 1 aumenta a 0.734 (1 - 0.266), que es equivalente a 0.5 + 0.234.\n",
    "En resumen, el comportamiento que estás observando es normal en un problema de clasificación binaria con `treeinterpreter`. Las contribuciones con la misma magnitud pero signo opuesto reflejan el impacto opuesto de la característica en la probabilidad de cada clase.\n",
    "\n",
    "Si observas este patrón en todas las características, significa que el modelo está utilizando las características para discriminar entre las dos clases de manera efectiva.\n",
    "\n",
    "Espero que esta explicación te ayude a comprender mejor el significado de las contribuciones en `treeinterpreter.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entiendo. El error \"UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\" indica que el objeto MinMaxScaler se ajustó con datos que tenían nombres de características (columnas), pero ahora se está utilizando para transformar datos que no tienen nombres de características.\n",
    "\n",
    "Esto puede suceder si estás utilizando un DataFrame de Pandas para entrenar el modelo y ajustar el escalador, pero luego estás utilizando un array NumPy para hacer predicciones. Los arrays NumPy no tienen nombres de características, por lo que el escalador no puede encontrar las características que espera.\n",
    "\n",
    "Para solucionar este problema, puedes intentar lo siguiente:\n",
    "\n",
    "1. Utilizar un DataFrame de Pandas para hacer predicciones:\n",
    "Si es posible, utiliza un DataFrame de Pandas para almacenar los datos de entrada que se utilizarán para hacer predicciones. Asegúrate de que el DataFrame tenga los mismos nombres de columnas que el DataFrame que se utilizó para entrenar el modelo y ajustar el escalador.\n",
    "\n",
    "2. Asignar nombres de características al array NumPy:\n",
    "Si no puedes utilizar un DataFrame de Pandas, puedes asignar nombres de características al array NumPy utilizando la función np.array con el argumento dtype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.array(input_data, dtype=[('feature1', float), ('feature2', float), ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reemplaza feature1, feature2, etc. con los nombres de las características que espera el escalador.\n",
    "\n",
    "3. Ignorar la advertencia:\n",
    "Si la advertencia no afecta el rendimiento del modelo, puedes ignorarla utilizando la función warnings.filterwarnings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', message='X does not have valid feature names, but')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, vamos a repasar la interpretación del MDI (Mean Decrease Impurity) con las barras y las líneas en medio, que representan la desviación estándar.\n",
    "\n",
    "**Interpretación del MDI:**\n",
    "\n",
    "* **Barras:** La altura de cada barra representa la importancia de la característica correspondiente en el modelo. Cuanto más alta sea la barra, más importante es la característica para la predicción del modelo.\n",
    "* **Líneas:** Las líneas en medio de las barras representan la desviación estándar de la importancia de la característica. La desviación estándar indica la variabilidad o incertidumbre en la importancia de la característica.\n",
    "\n",
    "En resumen:\n",
    "* Barras altas indican características importantes.\n",
    "* Líneas cortas indican una importancia más estable y confiable.\n",
    "* Líneas largas indican una importancia más variable e incierta.\n",
    "\n",
    "**Desviación estándar:**\n",
    "La desviación estándar es una medida de la dispersión de los datos alrededor de la media. En el contexto del MDI, una desviación estándar grande indica que la importancia de la característica varía mucho entre diferentes ejecuciones del modelo o entre diferentes subconjuntos de datos. Esto puede deberse a que la característica es menos importante o a que hay ruido en los datos.\n",
    "\n",
    "**Ejemplo:**\n",
    "Si una característica tiene una barra alta y una línea corta, significa que es una característica importante y su importancia es estable. Por otro lado, si una característica tiene una barra baja y una línea larga, significa que es una característica menos importante y su importancia es incierta.\n",
    "\n",
    "**En general, se deben prestar más atención a las características con barras altas y líneas cortas, ya que son las más importantes y confiables para la predicción del modelo.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buena pregunta. Si las líneas más altas (desviación estándar) solo están asociadas a las barras altas (importancia de la característica) y son proporcionales al tamaño de la barra, no necesariamente le resta importancia a las barras altas.\n",
    "\n",
    "Aquí te explico por qué:\n",
    "1. **Proporcionalidad:** La desviación estándar a menudo es proporcional a la magnitud de la medida. En este caso, es esperable que características con mayor importancia (barras altas) también tengan una mayor variabilidad en su importancia (líneas altas). Esto se debe a que las características más influyentes tienen un mayor impacto en el modelo y, por lo tanto, su importancia puede variar más entre diferentes ejecuciones o subconjuntos de datos.\n",
    "\n",
    "2. **Interpretación:** La clave es la proporción entre la altura de la barra y la longitud de la línea. Si la línea es muy larga en comparación con la altura de la barra, indica una mayor incertidumbre en la importancia de la característica, incluso si la barra es alta. Sin embargo, si la línea es proporcionalmente corta en relación con la altura de la barra, la característica sigue siendo considerada importante y confiable, a pesar de la variabilidad.\n",
    "\n",
    "3. **Enfoque:** En lugar de restarle importancia a las barras altas con líneas altas proporcionales, es mejor enfocarse en la relación entre la altura de la barra y la longitud de la línea. Si la proporción es similar entre diferentes características, las barras altas siguen siendo las más importantes, incluso con líneas altas.\n",
    "\n",
    "**En resumen:**\n",
    "* Las líneas altas proporcionales a las barras altas no invalidan la importancia de las características.\n",
    "* La proporción entre la altura de la barra y la longitud de la línea es clave para la interpretación.\n",
    "* Características con barras altas y líneas proporcionales siguen siendo importantes, pero con mayor variabilidad en su importancia.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
